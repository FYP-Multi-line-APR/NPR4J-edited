train_batch_size: 64
eval_batch_size: 16
beam_size: 10
max_source_length: 256
max_target_length: 128
output_dir: /home/zhongwenkang/NPR_Data/Models/CodeBERT-ft/save
train_prefix: /home/zhongwenkang/NPR_Data/TrainData/trn
train_steps: 50000
dev_prefix: /home/zhongwenkang/NPR_Data/TrainData/val
eval_steps: 1000
do_train: True
do_eval: True
do_test: False
model_type: roberta
model_name_or_path: /home/zhongwenkang/NPR_Data/Models/CodeBERT-ft/base/codebert-base
learning_rate: 5e-5

